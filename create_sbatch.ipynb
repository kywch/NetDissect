{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimal parameters\n",
    "\n",
    "# for more parameters, see settings.py\n",
    "\n",
    "job_name = \"netdissect1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python dissect.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cmd = \"python dissect.py\"\n",
    "\n",
    "print(cmd)\n",
    "\n",
    "# %%bash -s \"{job_name}\" \"{cmd}\" \"{save_dir}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=netdissect1\n",
      "#SBATCH --output=out_netdissect1.sbatch_err\n",
      "#SBATCH --error=err_netdissect1.sbatch_err\n",
      "#SBATCH --time=6:00:00\n",
      "#SBATCH --nodes=1\n",
      "#SBATCH --partition=gpu2\n",
      "#SBATCH --gres=gpu:1\n",
      "#SBATCH --ntasks-per-node=13\n",
      "#SBATCH --mem=64000\n",
      "\n",
      "module load cuda/9.0\n",
      "module load Anaconda3/5.0.1\n",
      "source activate fastai\n",
      "\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_00501.pth.tar result/checkpoint_001_00501\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_01001.pth.tar result/checkpoint_001_01001\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_01501.pth.tar result/checkpoint_001_01501\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_02001.pth.tar result/checkpoint_001_02001\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_02501.pth.tar result/checkpoint_001_02501\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_03001.pth.tar result/checkpoint_001_03001\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_03501.pth.tar result/checkpoint_001_03501\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_04001.pth.tar result/checkpoint_001_04001\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_04501.pth.tar result/checkpoint_001_04501\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_05001.pth.tar result/checkpoint_001_05001\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_05501.pth.tar result/checkpoint_001_05501\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_06001.pth.tar result/checkpoint_001_06001\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_06501.pth.tar result/checkpoint_001_06501\n",
      "python dissect.py resnet50_snapshots/checkpoint_001_07001.pth.tar result/checkpoint_001_07001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"{job_name}\" \"{cmd}\"\n",
    "echo \"#!/bin/bash\n",
    "#SBATCH --job-name=$1\n",
    "#SBATCH --output=out_$1.sbatch_err\n",
    "#SBATCH --error=err_$1.sbatch_err\n",
    "#SBATCH --time=6:00:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --partition=gpu2\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --ntasks-per-node=13\n",
    "#SBATCH --mem=64000\n",
    "\n",
    "module load cuda/9.0\n",
    "module load Anaconda3/5.0.1\n",
    "source activate fastai\n",
    "\n",
    "$2 resnet50_snapshots/checkpoint_001_00501.pth.tar result/checkpoint_001_00501\n",
    "$2 resnet50_snapshots/checkpoint_001_01001.pth.tar result/checkpoint_001_01001\n",
    "$2 resnet50_snapshots/checkpoint_001_01501.pth.tar result/checkpoint_001_01501\n",
    "$2 resnet50_snapshots/checkpoint_001_02001.pth.tar result/checkpoint_001_02001\n",
    "$2 resnet50_snapshots/checkpoint_001_02501.pth.tar result/checkpoint_001_02501\n",
    "$2 resnet50_snapshots/checkpoint_001_03001.pth.tar result/checkpoint_001_03001\n",
    "$2 resnet50_snapshots/checkpoint_001_03501.pth.tar result/checkpoint_001_03501\n",
    "$2 resnet50_snapshots/checkpoint_001_04001.pth.tar result/checkpoint_001_04001\n",
    "$2 resnet50_snapshots/checkpoint_001_04501.pth.tar result/checkpoint_001_04501\n",
    "$2 resnet50_snapshots/checkpoint_001_05001.pth.tar result/checkpoint_001_05001\n",
    "$2 resnet50_snapshots/checkpoint_001_05501.pth.tar result/checkpoint_001_05501\n",
    "$2 resnet50_snapshots/checkpoint_001_06001.pth.tar result/checkpoint_001_06001\n",
    "$2 resnet50_snapshots/checkpoint_001_06501.pth.tar result/checkpoint_001_06501\n",
    "$2 resnet50_snapshots/checkpoint_001_07001.pth.tar result/checkpoint_001_07001\n",
    "\n",
    "\" > $1.batch\n",
    "\n",
    "cat $1.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'003'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(3).zfill(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "    parser.add_argument('data', metavar='DIR',\n",
    "                        help='path to dataset')\n",
    "    parser.add_argument('--save-dir', type=str, default=Path.cwd(),\n",
    "                        help='Directory to save logs and models.')\n",
    "    parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet18',\n",
    "                        choices=model_names,\n",
    "                        help='model architecture: ' +\n",
    "                        ' | '.join(model_names) +\n",
    "                        ' (default: resnet18)')\n",
    "    parser.add_argument('-j', '--workers', default=7, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 7)')\n",
    "    parser.add_argument('--epochs', default=90, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                        help='manual epoch number (useful on restarts)')\n",
    "    parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                        metavar='N', help='mini-batch size (default: 256)')\n",
    "    parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                        metavar='LR', help='initial learning rate')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\n",
    "    parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                        metavar='W', help='weight decay (default: 1e-4)')\n",
    "    parser.add_argument('--print-freq', '-p', default=100, type=int,\n",
    "                        metavar='N', help='print frequency (default: 100)')\n",
    "    parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                        help='path to latest checkpoint (default: none)')\n",
    "    parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "                        help='evaluate model on validation set')\n",
    "    parser.add_argument('--pretrained', dest='pretrained', action='store_true', help='use pre-trained model')\n",
    "    parser.add_argument('--fp16', action='store_true', help='Run model fp16 mode.')\n",
    "    parser.add_argument('--dp', action='store_true', help='Run model fp16 mode.')\n",
    "    parser.add_argument('--sz',       default=224, type=int, help='Size of transformed image.')\n",
    "    parser.add_argument('--decay-int', default=30, type=int, help='Decay LR by 10 every decay-int epochs')\n",
    "    parser.add_argument('--loss-scale', type=float, default=1,\n",
    "                        help='Loss scaling, positive power of 2 values can improve fp16 convergence.')\n",
    "    parser.add_argument('--prof', dest='prof', action='store_true', help='Only run a few iters for profiling.')\n",
    "\n",
    "    parser.add_argument('--dist-url', default='file://sync.file', type=str,\n",
    "                        help='url used to set up distributed training')\n",
    "    parser.add_argument('--dist-backend', default='nccl', type=str, help='distributed backend')\n",
    "\n",
    "    parser.add_argument('--world-size', default=1, type=int,\n",
    "                        help='Number of GPUs to use. Can either be manually set ' +\n",
    "                        'or automatically set by using \\'python -m multiproc\\'.')\n",
    "    parser.add_argument('--rank', default=0, type=int,\n",
    "                        help='Used for multi-process training. Can either be manually set ' +\n",
    "                        'or automatically set by using \\'python -m multiproc\\'.')\n",
    "    \n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every few epochs\"\"\"\n",
    "    if   epoch<4 : lr = args.lr/(4-epoch)\n",
    "    elif epoch<28: lr = args.lr/1\n",
    "    elif epoch<47: lr = args.lr/10\n",
    "    elif epoch<57: lr = args.lr/100\n",
    "    else         : lr = args.lr/1000\n",
    "    for param_group in optimizer.param_groups: param_group['lr'] = lr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_models\n",
    "model = pytorch_models.__dict__['resnet50'](pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function resnet50_3 at 0x7f26201388c8>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
